{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the text cleaning and preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "def cleantext(string):\n",
    "    # Remove all punctuation\n",
    "    string = re.sub(r\"'s\\b\", '', string)\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    # Make all lowercase\n",
    "    string = string.lower()\n",
    "    # remove all stopwords\n",
    "    string = ' '.join([word for word in string.split() if word not in stopwords])\n",
    "    # Remove all special characters\n",
    "    string = re.sub(r'\\W+', ' ', string)\n",
    "    return string\n",
    "def lemmatize(string):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    string = ' '.join([lemmatizer.lemmatize(word) for word in string.split()])\n",
    "    return string\n",
    "def preprocess(obj):\n",
    "    obj = cleantext(obj)\n",
    "    obj = lemmatize(obj)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/news_data_labelled.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data['Text'] = data['Title'] + ' ' + data['Text']\n",
    "data['cleaned_text'] = data['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenise the text and convert to sequences of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1035707 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['cleaned_text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['cleaned_text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique tokens.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad the sequences to length of 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pad = pad_sequences(sequences, maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare labels for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(data['Sentiment']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_pad, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1, 100, input_length=400))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softmax'))  \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning through a coarse parameter grid search, to narrow values down to a smaller range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "832/832 [==============================] - 543s 651ms/step - loss: 0.6068 - accuracy: 0.7642 - val_loss: 0.5333 - val_accuracy: 0.8041\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 589s 708ms/step - loss: 0.3347 - accuracy: 0.8866 - val_loss: 0.5078 - val_accuracy: 0.8196\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 545s 654ms/step - loss: 0.1752 - accuracy: 0.9437 - val_loss: 1.0081 - val_accuracy: 0.6839\n",
      "Params: {'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 64}, Score: 0.8196427226066589\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 802s 963ms/step - loss: 0.6291 - accuracy: 0.7478 - val_loss: 0.5198 - val_accuracy: 0.8079\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 769s 924ms/step - loss: 0.3799 - accuracy: 0.8646 - val_loss: 0.6503 - val_accuracy: 0.7322\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 895s 1s/step - loss: 0.2557 - accuracy: 0.9130 - val_loss: 0.6256 - val_accuracy: 0.8089\n",
      "Params: {'dropout_rate': 0.2, 'learning_rate': 0.01, 'lstm_units': 128}, Score: 0.8088504076004028\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 654s 784ms/step - loss: 0.6297 - accuracy: 0.7499 - val_loss: 0.5683 - val_accuracy: 0.7925\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 545s 655ms/step - loss: 0.3704 - accuracy: 0.8694 - val_loss: 0.5831 - val_accuracy: 0.8172\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 813s 977ms/step - loss: 0.2193 - accuracy: 0.9282 - val_loss: 0.5741 - val_accuracy: 0.8126\n",
      "Params: {'dropout_rate': 0.2, 'learning_rate': 0.001, 'lstm_units': 64}, Score: 0.817206859588623\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 887s 1s/step - loss: 0.6567 - accuracy: 0.7371 - val_loss: 0.5769 - val_accuracy: 0.7867\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 902s 1s/step - loss: 0.3748 - accuracy: 0.8680 - val_loss: 0.4718 - val_accuracy: 0.8272\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 878s 1s/step - loss: 0.1980 - accuracy: 0.9355 - val_loss: 0.5785 - val_accuracy: 0.8261\n",
      "Params: {'dropout_rate': 0.2, 'learning_rate': 0.001, 'lstm_units': 128}, Score: 0.8272210359573364\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 672s 806ms/step - loss: 0.6402 - accuracy: 0.7562 - val_loss: 0.6222 - val_accuracy: 0.7710\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 652s 784ms/step - loss: 0.4012 - accuracy: 0.8612 - val_loss: 0.5395 - val_accuracy: 0.7941\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 648s 779ms/step - loss: 0.2237 - accuracy: 0.9277 - val_loss: 0.5487 - val_accuracy: 0.8213\n",
      "Params: {'dropout_rate': 0.4, 'learning_rate': 0.01, 'lstm_units': 64}, Score: 0.8213343024253845\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 949s 1s/step - loss: 0.6677 - accuracy: 0.7367 - val_loss: 0.6455 - val_accuracy: 0.7566\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 682s 819ms/step - loss: 0.4686 - accuracy: 0.8315 - val_loss: 0.5562 - val_accuracy: 0.7853\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 705s 847ms/step - loss: 0.3306 - accuracy: 0.8857 - val_loss: 0.6981 - val_accuracy: 0.6695\n",
      "Params: {'dropout_rate': 0.4, 'learning_rate': 0.01, 'lstm_units': 128}, Score: 0.7853373289108276\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 58414s 70s/step - loss: 0.6227 - accuracy: 0.7525 - val_loss: 0.5300 - val_accuracy: 0.8032\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 492s 591ms/step - loss: 0.3504 - accuracy: 0.8823 - val_loss: 0.5143 - val_accuracy: 0.8185\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 511s 614ms/step - loss: 0.1990 - accuracy: 0.9375 - val_loss: 0.6087 - val_accuracy: 0.8118\n",
      "Params: {'dropout_rate': 0.4, 'learning_rate': 0.001, 'lstm_units': 64}, Score: 0.818458616733551\n",
      "Epoch 1/3\n",
      "832/832 [==============================] - 682s 818ms/step - loss: 0.6852 - accuracy: 0.7276 - val_loss: 0.8703 - val_accuracy: 0.5637\n",
      "Epoch 2/3\n",
      "832/832 [==============================] - 703s 844ms/step - loss: 0.4015 - accuracy: 0.8586 - val_loss: 0.5218 - val_accuracy: 0.8022\n",
      "Epoch 3/3\n",
      "832/832 [==============================] - 620s 745ms/step - loss: 0.2457 - accuracy: 0.9190 - val_loss: 0.6284 - val_accuracy: 0.7990\n",
      "Params: {'dropout_rate': 0.4, 'learning_rate': 0.001, 'lstm_units': 128}, Score: 0.8021516799926758\n",
      "Best params: {'dropout_rate': 0.2, 'learning_rate': 0.001, 'lstm_units': 128}, Best score: 0.8272210359573364\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'lstm_units': [64, 128],\n",
    "    'dropout_rate': [0.2, 0.4],\n",
    "    'learning_rate': [0.01, 0.001]\n",
    "}\n",
    "\n",
    "# This will generate all combinations of parameters\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Placeholder for best score and best params\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "# Iterate over all combinations\n",
    "for params in grid:\n",
    "    # Create a new model with current params\n",
    "    model = create_model(lstm_units=params['lstm_units'],\n",
    "                         dropout_rate=params['dropout_rate'],\n",
    "                         learning_rate=params['learning_rate'])\n",
    "    \n",
    "    # Train the model (use a smaller subset of data for speed)\n",
    "    history = model.fit(X_train[:int(len(X_train)*0.1)], y_train[:int(len(y_train)*0.1)],\n",
    "                        batch_size=32,\n",
    "                        epochs=3,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "    \n",
    "    # Check if the performance is improved\n",
    "    score = max(history.history['val_accuracy'])  # Use the best epoch's accuracy\n",
    "    print(f\"Params: {params}, Score: {score}\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best params: {best_params}, Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing smaller range to find optimal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lstm_units=64, dropout_rate=0.2, learning_rate=0.01, lstm_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(word_index) + 1, output_dim=100, input_length=400))\n",
    "    for i in range(lstm_layers):\n",
    "        return_sequences = i < lstm_layers - 1  # Only the last LSTM layer has return_sequences=False\n",
    "        model.add(LSTM(lstm_units, return_sequences=return_sequences))\n",
    "        if return_sequences:  # Optionally add dropout after each LSTM layer except the last one\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softmax'))  # Assuming 3 classes for the output layer\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define a new grid with narrowed down parameters and including the number of LSTM layers\n",
    "param_grid = {\n",
    "    'lstm_units': [64],  # Narrowed down to the best value from the previous search\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],  # Slightly broader around the best value\n",
    "    'learning_rate': [0.005, 0.01, 0.02],  # Slightly broader around the best value\n",
    "    'lstm_layers': [1, 2]  # Testing both 1 and 2 layers\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Iterate over the grid\n",
    "for params in grid:\n",
    "    model = create_model(lstm_units=params['lstm_units'],\n",
    "                         dropout_rate=params['dropout_rate'],\n",
    "                         learning_rate=params['learning_rate'],\n",
    "                         lstm_layers=params['lstm_layers'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, \n",
    "                        batch_size=32, \n",
    "                        epochs=3,  # Assuming you want to keep epochs low for quick iterations\n",
    "                        validation_data=(X_val, y_val), \n",
    "                        callbacks=[early_stopping])\n",
    "    \n",
    "    # Use the best epoch's accuracy as the score\n",
    "    score = max(history.history['val_accuracy'])\n",
    "    print(f\"Params: {params}, Validation Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8314/8314 [==============================] - 6824s 820ms/step - loss: 0.3289 - accuracy: 0.8787 - val_loss: 0.2284 - val_accuracy: 0.9179\n",
      "Epoch 2/3\n",
      "8314/8314 [==============================] - 6045s 727ms/step - loss: 0.1923 - accuracy: 0.9319 - val_loss: 0.2032 - val_accuracy: 0.9250\n",
      "Epoch 3/3\n",
      "8314/8314 [==============================] - 5582s 671ms/step - loss: 0.1532 - accuracy: 0.9451 - val_loss: 0.2101 - val_accuracy: 0.9263\n"
     ]
    }
   ],
   "source": [
    "final_model = create_model(lstm_units=64,\n",
    "                         dropout_rate=0.1,\n",
    "                         learning_rate=0.005,\n",
    "                         lstm_layers=2)\n",
    "history = final_model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=3,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.21009482443332672\n",
      "Validation Accuracy: 0.9263482093811035\n"
     ]
    }
   ],
   "source": [
    "score = final_model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Validation Loss:', score[0])\n",
    "print('Validation Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "final_model.save('../Finalised_Models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return continous output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess(text)\n",
    "    \n",
    "    # Tokenize and pad the text\n",
    "    sequence = tokenizer.texts_to_sequences([preprocessed_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=400)\n",
    "    \n",
    "    # Get the model's prediction (probabilities for each class)\n",
    "    prediction = final_model.predict(padded_sequence)[0]\n",
    "    \n",
    "    # Assuming the order of output probabilities is [negative, neutral, positive]\n",
    "    # We can take a weighted sum of the probabilities and the sentiment scores\n",
    "    sentiment_score = (prediction[0] * -1) + (prediction[1] * 0) + (prediction[2] * 1)\n",
    "    \n",
    "\n",
    "    return sentiment_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
